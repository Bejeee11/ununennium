{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 40 - ONNX Export\n",
                "\n",
                "**Purpose**: Export models to ONNX format.\n",
                "\n",
                "This notebook demonstrates key functionality with synthetic data."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Installation (Kaggle/Colab)\n",
                "\n",
                "Run this cell to install the library if running on Kaggle or Google Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment the following line to install ununennium\n",
                "# !pip install -q ununennium[export]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prerequisites and Environment Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Python: 3.12.10 (tags/v3.12.10:0cc8128, Apr  8 2025, 12:21:36) [MSC v.1943 64 bit (AMD64)]\n",
                        "PyTorch: 2.9.1+cpu\n",
                        "CUDA: False\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import torch\n",
                "import numpy as np\n",
                "\n",
                "print(f'Python: {sys.version}')\n",
                "print(f'PyTorch: {torch.__version__}')\n",
                "print(f'CUDA: {torch.cuda.is_available()}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reproducibility"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEED = 42\n",
                "torch.manual_seed(SEED)\n",
                "np.random.seed(SEED)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Core Workflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from ununennium.models import create_model\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "W1216 11:30:11.767000 1988 torch\\onnx\\_internal\\exporter\\_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[torch.onnx] Obtain model graph for `UNet([...]` with `torch.export.export(..., strict=False)`...\n",
                        "[torch.onnx] Obtain model graph for `UNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
                        "[torch.onnx] Run decomposition...\n",
                        "[torch.onnx] Run decomposition... ✅\n",
                        "[torch.onnx] Translate the graph into ONNX...\n",
                        "[torch.onnx] Translate the graph into ONNX... ✅\n",
                        "Applied 78 of general pattern rewrite rules.\n",
                        "Exported to ONNX\n"
                    ]
                }
            ],
            "source": [
                "model = create_model('unet', in_channels=4, num_classes=5, backbone='resnet18', pretrained=False)\n",
                "model.eval()\n",
                "dummy = torch.randn(1, 4, 256, 256)\n",
                "Path('artifacts/notebooks/40').mkdir(parents=True, exist_ok=True)\n",
                "# Use opset_version=18 to match PyTorch 2.4+ exporter capabilities\n",
                "torch.onnx.export(model, dummy, 'artifacts/notebooks/40/model.onnx', opset_version=18)\n",
                "print('Exported to ONNX')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Notebook validation passed\n"
                    ]
                }
            ],
            "source": [
                "# All cells executed successfully\n",
                "print('Notebook validation passed')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Artifacts directory: artifacts\\notebooks\\40\n"
                    ]
                }
            ],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "ARTIFACT_DIR = Path('artifacts/notebooks/40')\n",
                "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "print(f'Artifacts directory: {ARTIFACT_DIR}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "See the [notebooks README](README.md) for related tutorials."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
